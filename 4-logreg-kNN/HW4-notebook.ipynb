{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#4 - Portland houses\n",
    "df_full = pd.read_table(\"portland_houses.txt\", sep = \",\", names = [\"Area\",\"Bedrooms\",\"Price\"])\n",
    "df = df_full[[\"Area\",\"Price\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#4a - normal distribution model + sampling\n",
    "\n",
    "areas = df['Area']\n",
    "\n",
    "B_0 = 90000\n",
    "B_1 = 140\n",
    "sigma = 65000\n",
    "\n",
    "def draw_Y(xin):\n",
    "    eps = np.random.normal(loc=0.0,scale=sigma)\n",
    "    return B_0 + B_1*xin + eps\n",
    "\n",
    "Num_samples = 1000\n",
    "all_samples = []\n",
    "for i in range(0,Num_samples):\n",
    "    sample_ys = []\n",
    "    for area in areas:\n",
    "        sample_ys.append(draw_Y(area))\n",
    "    all_samples.append(sample_ys)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29051384.212765954"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4b S_xx\n",
    "\n",
    "Sxx = 0.\n",
    "area_mean = np.mean(areas)\n",
    "for area in areas:\n",
    "    Sxx += (area - area_mean)**2\n",
    "Sxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#4c - estimate parameters for each sample\n",
    "\n",
    "sample_B0s = []\n",
    "sample_B1s = []\n",
    "\n",
    "to_fit = np.transpose(np.asarray([np.asarray(areas), np.ones(len(areas))]))\n",
    "\n",
    "for i in range(0,Num_samples):\n",
    "    outs = np.linalg.lstsq(to_fit,np.asarray(all_samples[i]).reshape(-1,1))[0]\n",
    "    sample_B0s.append(outs[1][0])\n",
    "    sample_B1s.append(outs[0][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  4,  22, 134, 245, 282, 184,  87,  31,   8,   3], dtype=int64),\n",
       " array([  6.42082954e+10,   9.28812093e+10,   1.21554123e+11,\n",
       "          1.50227037e+11,   1.78899951e+11,   2.07572865e+11,\n",
       "          2.36245779e+11,   2.64918693e+11,   2.93591607e+11,\n",
       "          3.22264521e+11,   3.50937434e+11]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4e - get sum of square of residues for each sample\n",
    "\n",
    "SSRs = []\n",
    "\n",
    "for i in range(0, Num_samples):\n",
    "    currB0 = sample_B0s[i]\n",
    "    currB1 = sample_B1s[i]\n",
    "    currSSR = 0.\n",
    "    for j in range(0,len(areas)):\n",
    "        currSSR += (all_samples[i][j] - (currB0 + currB1*areas[j]))**2\n",
    "    SSRs.append(currSSR)\n",
    "\n",
    "    \n",
    "    \n",
    "SSR_scaled = []\n",
    "for SSR in SSRs:\n",
    "    SSR_scaled.append(SSR*1./sigma**2)\n",
    "\n",
    "np.histogram(SSRs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_0: Predicted, Experimental (N = 1000)\n",
      "Mean: 90000, 90263.1512008\n",
      "Stdev: 25923.3028248, 27150.281981\n",
      "\n",
      "B_1: Predicted, Experimental (N = 1000)\n",
      "Mean: 140, 139.84693586\n",
      "Stdev: 12.0595177647, 12.6396017075\n",
      "\n",
      "SSR: Predicted, Experimental (N = 1000)\n",
      "Mean: 45, 45.0829917381\n",
      "Variance: 90, 92.3086183572\n"
     ]
    }
   ],
   "source": [
    "#4f - quantile-quantile plot\n",
    "from scipy.stats import probplot, chi2\n",
    "\n",
    "B0_theo_mean = B_0\n",
    "B0_theo_scale = ((np.dot(areas,areas)*sigma**2)*1./(Sxx*len(areas)))**.5\n",
    "B0arr = np.asarray(sample_B0s)\n",
    "\n",
    "print(\"B_0: Predicted, Experimental (N = \" + str(Num_samples) + \")\")\n",
    "print(\"Mean: \" + str(B0_theo_mean) + \", \" + str(np.mean(B0arr)))\n",
    "print(\"Stdev: \" + str(B0_theo_scale) + \", \" + str(np.var(B0arr)**.5))\n",
    "\n",
    "\n",
    "\n",
    "B1_theo_mean = B_1\n",
    "B1_theo_scale = sigma/((Sxx)**.5)\n",
    "B1arr = np.asarray(sample_B1s)\n",
    "\n",
    "print(\"\\nB_1: Predicted, Experimental (N = \" + str(Num_samples) + \")\")\n",
    "print(\"Mean: \" + str(B1_theo_mean) + \", \" + str(np.mean(B1arr)))\n",
    "print(\"Stdev: \" + str(B1_theo_scale) + \", \" + str(np.var(B1arr)**.5))\n",
    "\n",
    "\n",
    "SSRarr = np.asarray(SSR_scaled)\n",
    "\n",
    "print(\"\\nSSR: Predicted, Experimental (N = \" + str(Num_samples) + \")\")\n",
    "print(\"Mean: \" + str(len(areas)-2) + \", \" + str(np.mean(SSRarr)))\n",
    "print(\"Variance: \" + str((len(areas)-2)*2) + \", \" + str(np.var(SSRarr)))\n",
    "\n",
    "\n",
    "## non working code to make plots fancier\n",
    "# plt.title(\"Scaled B_0 normal probability plot - N = \" + str(Num_samples))\n",
    "# plt.text(\"Test\", 1,1)\n",
    "plt.clf()\n",
    "probplot((B0arr-B0_theo_mean)/B0_theo_scale, dist = 'norm', plot = plt, fit = False)\n",
    "# plt.savefig(\"B0-probplot-N\" + str(Num_samples))\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "probplot((B1arr-B1_theo_mean)/B1_theo_scale, plot = plt, fit = False)\n",
    "# plt.savefig(\"B1-probplot-N\" + str(Num_samples))\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "probplot(SSRarr, dist = chi2, sparams = (len(areas)-2.), plot = plt)\n",
    "# plt.savefig(\"SSR-QQplot-N\" + str(Num_samples))\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# B_0: Predicted, Experimental (N = 200)\n",
    "# Mean: 90000, 91214.275027\n",
    "# Stdev: 25923.3028248, 26216.1848178\n",
    "\n",
    "# B_1: Predicted, Experimental (N = 200)\n",
    "# Mean: 140, 139.390008812\n",
    "# Stdev: 12.0595177647, 12.3368098799\n",
    "\n",
    "# SSR: Predicted, Experimental (N = 200)\n",
    "# Mean: 45, 45.0307825641\n",
    "# Variance: 90, 93.4425402582\n",
    "\n",
    "\n",
    "# B_0: Predicted, Experimental (N = 1000)\n",
    "# Mean: 90000, 88526.303228\n",
    "# Stdev: 25923.3028248, 25365.1801909\n",
    "\n",
    "# B_1: Predicted, Experimental (N = 1000)\n",
    "# Mean: 140, 140.577950748\n",
    "# Stdev: 12.0595177647, 11.7795330282\n",
    "\n",
    "# SSR: Predicted, Experimental (N = 1000)\n",
    "# Mean: 45, 44.7957608198\n",
    "# Variance: 90, 87.3393505881"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input_0</th>\n",
       "      <th>Input_1</th>\n",
       "      <th>Input_2</th>\n",
       "      <th>Input_3</th>\n",
       "      <th>Input_4</th>\n",
       "      <th>Input_5</th>\n",
       "      <th>Input_6</th>\n",
       "      <th>Input_7</th>\n",
       "      <th>Input_8</th>\n",
       "      <th>Input_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Input_270</th>\n",
       "      <th>Input_271</th>\n",
       "      <th>Input_272</th>\n",
       "      <th>Input_273</th>\n",
       "      <th>Input_274</th>\n",
       "      <th>Input_275</th>\n",
       "      <th>Input_276</th>\n",
       "      <th>Input_277</th>\n",
       "      <th>Input_278</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>91</td>\n",
       "      <td>193</td>\n",
       "      <td>371</td>\n",
       "      <td>174</td>\n",
       "      <td>121</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>49.4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>81</td>\n",
       "      <td>174</td>\n",
       "      <td>401</td>\n",
       "      <td>149</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>38.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>95</td>\n",
       "      <td>138</td>\n",
       "      <td>163</td>\n",
       "      <td>386</td>\n",
       "      <td>185</td>\n",
       "      <td>102</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Input_0  Input_1  Input_2  Input_3  Input_4  Input_5  Input_6  Input_7  \\\n",
       "0       75        0      190       80       91      193      371      174   \n",
       "1       56        1      165       64       81      174      401      149   \n",
       "2       54        0      172       95      138      163      386      185   \n",
       "\n",
       "   Input_8  Input_9   ...    Input_270  Input_271  Input_272  Input_273  \\\n",
       "0      121      -16   ...          0.0        9.0       -0.9        0.0   \n",
       "1       39       25   ...          0.0        8.5        0.0        0.0   \n",
       "2      102       96   ...          0.0        9.5       -2.4        0.0   \n",
       "\n",
       "   Input_274  Input_275  Input_276  Input_277  Input_278  Output  \n",
       "0        0.0        0.9        2.9       23.3       49.4       8  \n",
       "1        0.0        0.2        2.1       20.4       38.8       6  \n",
       "2        0.0        0.3        3.4       12.3       49.0      10  \n",
       "\n",
       "[3 rows x 280 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5 - Arrhythmia data\n",
    "\n",
    "#5a - load and clean dataset\n",
    "\n",
    "arr_names = []\n",
    "for i in range(0,279):\n",
    "    arr_names.append(\"Input_\" + str(i))\n",
    "    \n",
    "arr_names.append(\"Output\")\n",
    "\n",
    "dfa = pd.read_table(\"arrhythmia.data\", sep = \",\", header = None, names=arr_names, na_values = [\"?\"])\n",
    "\n",
    "dfa[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "452\n"
     ]
    }
   ],
   "source": [
    "# for col in df_arr.columns:\n",
    "#     print(df_arr[col].dtype)\n",
    "\n",
    "print(dfa['Input_13'][3])\n",
    "outcount = 0\n",
    "for i in range(0,len(dfa['Output'])):\n",
    "    currn = dfa['Output'][i]\n",
    "    outcount += 1\n",
    "    if(np.isnan(currn)):\n",
    "        print(i)\n",
    "print(outcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "#impute mean for integer, float; impute mode otherwise\n",
    "\n",
    "\n",
    "def categorical_to_int(cat_col):\n",
    "    int_col = []\n",
    "    catmap = {}\n",
    "    currind = 0\n",
    "    for val in cat_col:\n",
    "        if val not in catmap.keys():\n",
    "            catmap[val] = currind\n",
    "            int_col.append(currind)\n",
    "            currind += 1\n",
    "        else:\n",
    "            int_col.append(catmap[val])\n",
    "    return int_col\n",
    "\n",
    "def imputed_version(dfin, excl_cols = []):\n",
    "    df = dfin.copy()\n",
    "    \n",
    "    copyimputed = False\n",
    "    imp_mean = Imputer(missing_values='NaN', strategy='mean', axis=0,copy=copyimputed)\n",
    "    imp_mode = Imputer(missing_values='NaN', strategy='most_frequent', axis=0, copy=copyimputed )\n",
    "\n",
    "    categorical_vars = []\n",
    "    #will use this list to make dummies for all categorical variables\n",
    "\n",
    "    for col in df.columns:\n",
    "        if(col in excl_cols):\n",
    "            continue\n",
    "        elif(df[col].dtype == np.float64 or  df[col].dtype == np.int64):\n",
    "            df[col] = imp_mean.fit_transform(df[col].reshape(-1,1))    \n",
    "        else:\n",
    "            categorical_vars.append(col)\n",
    "            #need to convert to integer column for Imputer to work\n",
    "            df[col] = categorical_to_int(df[col])\n",
    "            df[col] = imp_mode.fit_transform(df[col].reshape(-1,1))  \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfa = imputed_version(dfa, ['Output'])\n",
    "# print(dfa['Input_13'][3])\n",
    "# print(np.mean(dfa['Input_13'][:]))\n",
    "\n",
    "X = np.asarray(dfa[arr_names[:279]])\n",
    "y = np.asarray(dfa['Output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(452, 279)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5b - grid search on knn classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "knc = KNeighborsClassifier(n_jobs = -1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=3, p=2,\n",
      "           weights='distance')\n",
      "0.494461222136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# n_neighbors = [3,10,30,100]\n",
    "#best pair was 3, distance\n",
    "n_neighbors = [3,4,5,7]\n",
    "#best pair was still 3, distance, with a score of 0.494461222136\n",
    "\n",
    "weights = ['uniform','distance']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "search_grid = {'n_neighbors':n_neighbors, 'weights': weights}\n",
    "\n",
    "\n",
    "gscv = GridSearchCV(knc,search_grid, cv=2, scoring='f1_weighted')\n",
    "gscv.fit(X,y)\n",
    "print(gscv.best_estimator_)\n",
    "print(gscv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#5b continued - learning curve for optimal predictor\n",
    "from sklearn.learning_curve import learning_curve\n",
    "\n",
    "\n",
    "knc_o = KNeighborsClassifier(n_neighbors = 3, weights = 'distance')\n",
    "lc_sizes, train_scores, test_scores = learning_curve(knc_o, X, y, cv = 2, scoring = 'f1_weighted')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_avg = np.average(train_scores,axis=1)\n",
    "test_avg = np.average(test_scores,axis=1)\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(lc_sizes, train_avg, 'go')\n",
    "plt.plot(lc_sizes, test_avg, 'ro')\n",
    "plt.title(\"Arrhythmia - kNN Learning Curve - f1_weighted scoring - all variables\")\n",
    "plt.savefig(\"knn_learningcurve_allvars\")\n",
    "\n",
    "#we can see that the training error is essentially zero, while test error is quite large\n",
    "#thus, most error comes from overfitting to the training set, or \"variance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.0005, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "0.656931022422\n"
     ]
    }
   ],
   "source": [
    "#5c - grid search for logistic regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lrg = LogisticRegression()\n",
    "\n",
    "# C = [.1,1.,3.,10.,30.,100.]\n",
    "#best was .1, l1\n",
    "\n",
    "# C = [.001,.01,.1,.2,.3]\n",
    "#best was .001, l2, with f1 weighted score of .65388\n",
    "\n",
    "# C = [.0003,.001,.003]\n",
    "#best was still .001, l2\n",
    "\n",
    "C = [.0005,.0008,.0012,.0015]\n",
    "#best was .0005, l2 with score of .65693\n",
    "# know best local C for l2 is between .0003, .001, and marginal value of tweaking C in this range does not seem high \n",
    "penalty = ['l1','l2']\n",
    "\n",
    "\n",
    "\n",
    "# #check - compare C over broad range to be sure previous inferences were correct\n",
    "# C = [.0001,.0005,1.,10.,30.]\n",
    "# penalty = ['l2']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "search_gridL = {'C':C, 'penalty': penalty}\n",
    "\n",
    "\n",
    "gscvL = GridSearchCV(lrg,search_gridL, cv=2, scoring='f1_weighted')\n",
    "gscvL.fit(X,y)\n",
    "print(gscvL.best_estimator_)\n",
    "print(gscvL.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "lrg_o = LogisticRegression(C = .0005, penalty = 'l2')\n",
    "\n",
    "lc_sizes, train_scores, test_scores = learning_curve(lrg_o, X, y, cv = 2, scoring = 'f1_weighted')\n",
    "\n",
    "train_avg = np.average(train_scores,axis=1)\n",
    "test_avg = np.average(test_scores,axis=1)\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(lc_sizes, train_avg, 'go')\n",
    "plt.plot(lc_sizes, test_avg, 'ro')\n",
    "plt.title(\"Arrhythmia - log reg Learning Curve - f1_weighted scoring\")\n",
    "# plt.show()\n",
    "plt.savefig(\"logreg_learningcurve\")\n",
    "#here we can see that error is due to a mix of bias and variance, though variance still dominates. \n",
    "#The score of this estimator is significantly better than that of the best kNN classifier\n",
    "#So I would recommend logistic regression over a k-nearest-neighbors approach which uses all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#5d - finding best beatures and running knn on them\n",
    "#find best features with forward search\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just included 17 variables: best score so far is 0.716803760282, with 17 variables used\n",
      "Input_0: changes score by -0.119506462985\n",
      "Input_1: changes score by -0.0397571484528\n",
      "Input_2: changes score by -0.0862710536623\n",
      "Input_3: changes score by -0.112749706228\n",
      "Input_4: changes score by -0.042009400705\n",
      "Input_5: changes score by -0.131844888367\n",
      "Input_6: changes score by -0.0862710536623\n",
      "Input_7: changes score by -0.0993145319232\n",
      "Input_8: changes score by -0.0772620446533\n",
      "Input_9: changes score by -0.147610654132\n",
      "Input_10: changes score by -0.0865844104974\n",
      "Input_11: changes score by -0.101723462593\n",
      "Input_12: changes score by -0.141402271837\n",
      "Input_13: changes score by -0.0503916960438\n",
      "Input_15: changes score by -0.0482961222091\n",
      "Input_16: changes score by -0.0972972972973\n",
      "Input_17: changes score by -0.0971406188797\n",
      "Input_18: changes score by -0.00225225225223\n",
      "Input_20: changes score by -0.108401880141\n",
      "Input_22: changes score by 2.12052597703e-14\n",
      "Input_23: changes score by 2.12052597703e-14\n",
      "Input_24: changes score by 2.12052597703e-14\n",
      "Input_25: changes score by 2.12052597703e-14\n",
      "Input_26: changes score by 2.12052597703e-14\n",
      "Input_27: changes score by -0.0266353309831\n",
      "Input_28: changes score by -0.108010184097\n",
      "Input_29: changes score by -0.105914610262\n",
      "Input_30: changes score by -0.00675675675674\n",
      "Input_31: changes score by -0.00225225225223\n",
      "Input_32: changes score by -0.0750097924011\n",
      "Input_33: changes score by 2.12052597703e-14\n",
      "Input_34: changes score by -0.00217391304346\n",
      "Input_35: changes score by 2.12052597703e-14\n",
      "Input_36: changes score by 2.12052597703e-14\n",
      "Input_37: changes score by 2.12052597703e-14\n",
      "Input_38: changes score by 2.12052597703e-14\n",
      "Input_39: changes score by -0.0639835487661\n",
      "Input_40: changes score by -0.134488836663\n",
      "Input_41: changes score by -0.0989228358793\n",
      "Input_42: changes score by -0.0261652957305\n",
      "Input_43: changes score by 2.12052597703e-14\n",
      "Input_44: changes score by -0.136741088915\n",
      "Input_45: changes score by 2.12052597703e-14\n",
      "Input_47: changes score by 2.12052597703e-14\n",
      "Input_48: changes score by 2.12052597703e-14\n",
      "Input_49: changes score by 2.12052597703e-14\n",
      "Input_50: changes score by 2.12052597703e-14\n",
      "Input_51: changes score by -0.0641402271837\n",
      "Input_52: changes score by -0.0771053662358\n",
      "Input_53: changes score by -0.0241480611046\n",
      "Input_54: changes score by -0.0198785742264\n",
      "Input_55: changes score by 2.12052597703e-14\n",
      "Input_56: changes score by -0.0861143752448\n",
      "Input_57: changes score by 2.12052597703e-14\n",
      "Input_58: changes score by 2.12052597703e-14\n",
      "Input_59: changes score by 2.12052597703e-14\n",
      "Input_60: changes score by 2.12052597703e-14\n",
      "Input_61: changes score by 2.12052597703e-14\n",
      "Input_62: changes score by 2.12052597703e-14\n",
      "Input_63: changes score by -0.0726008617313\n",
      "Input_64: changes score by -0.124010967489\n",
      "Input_65: changes score by -0.0946533490012\n",
      "Input_66: changes score by -0.00225225225223\n",
      "Input_67: changes score by 2.12052597703e-14\n",
      "Input_68: changes score by -0.119114766941\n",
      "Input_69: changes score by 2.12052597703e-14\n",
      "Input_70: changes score by 2.12052597703e-14\n",
      "Input_71: changes score by 2.12052597703e-14\n",
      "Input_72: changes score by 2.12052597703e-14\n",
      "Input_73: changes score by 2.12052597703e-14\n",
      "Input_74: changes score by 2.12052597703e-14\n",
      "Input_76: changes score by -0.135428907168\n",
      "Input_77: changes score by -0.0924794359577\n",
      "Input_78: changes score by -0.00434782608694\n",
      "Input_79: changes score by -0.00225225225223\n",
      "Input_80: changes score by -0.0680963572268\n",
      "Input_81: changes score by 2.12052597703e-14\n",
      "Input_82: changes score by 2.12052597703e-14\n",
      "Input_83: changes score by 2.12052597703e-14\n",
      "Input_84: changes score by 2.12052597703e-14\n",
      "Input_85: changes score by 2.12052597703e-14\n",
      "Input_86: changes score by 2.12052597703e-14\n",
      "Input_87: changes score by -0.0503916960438\n",
      "Input_88: changes score by -0.077027027027\n",
      "Input_89: changes score by -0.0814531923227\n",
      "Input_91: changes score by 2.12052597703e-14\n",
      "Input_92: changes score by -0.077027027027\n",
      "Input_93: changes score by 2.12052597703e-14\n",
      "Input_94: changes score by 2.12052597703e-14\n",
      "Input_95: changes score by -0.00434782608694\n",
      "Input_96: changes score by 2.12052597703e-14\n",
      "Input_97: changes score by -0.00434782608694\n",
      "Input_99: changes score by -0.0130434782608\n",
      "Input_100: changes score by -0.0885233059146\n",
      "Input_101: changes score by -0.0885233059146\n",
      "Input_103: changes score by 2.12052597703e-14\n",
      "Input_104: changes score by -0.0837837837838\n",
      "Input_105: changes score by 2.12052597703e-14\n",
      "Input_106: changes score by 2.12052597703e-14\n",
      "Input_107: changes score by 2.12052597703e-14\n",
      "Input_108: changes score by 2.12052597703e-14\n",
      "Input_110: changes score by -0.00675675675674\n",
      "Input_112: changes score by -0.0973756365061\n",
      "Input_113: changes score by -0.0550528789659\n",
      "Input_115: changes score by 2.12052597703e-14\n",
      "Input_116: changes score by -0.0689580885233\n",
      "Input_117: changes score by 2.12052597703e-14\n",
      "Input_118: changes score by 2.12052597703e-14\n",
      "Input_119: changes score by 2.12052597703e-14\n",
      "Input_120: changes score by 2.12052597703e-14\n",
      "Input_122: changes score by 2.12052597703e-14\n",
      "Input_123: changes score by -0.0264003133568\n",
      "Input_124: changes score by -0.0884449667058\n",
      "Input_125: changes score by -0.0924794359577\n",
      "Input_126: changes score by -0.00885233059144\n",
      "Input_127: changes score by 2.12052597703e-14\n",
      "Input_128: changes score by -0.0864277320799\n",
      "Input_129: changes score by 2.12052597703e-14\n",
      "Input_130: changes score by 2.12052597703e-14\n",
      "Input_131: changes score by 2.12052597703e-14\n",
      "Input_132: changes score by 2.12052597703e-14\n",
      "Input_133: changes score by 2.12052597703e-14\n",
      "Input_134: changes score by 2.12052597703e-14\n",
      "Input_135: changes score by -0.0397571484528\n",
      "Input_136: changes score by -0.0749314531923\n",
      "Input_137: changes score by -0.105366235801\n",
      "Input_138: changes score by -0.00442616529571\n",
      "Input_139: changes score by 2.12052597703e-14\n",
      "Input_140: changes score by -0.0533490011751\n",
      "Input_141: changes score by 2.12052597703e-14\n",
      "Input_142: changes score by 2.12052597703e-14\n",
      "Input_143: changes score by 2.12052597703e-14\n",
      "Input_144: changes score by 2.12052597703e-14\n",
      "Input_145: changes score by 2.12052597703e-14\n",
      "Input_146: changes score by 2.12052597703e-14\n",
      "Input_147: changes score by -0.0635918527223\n",
      "Input_148: changes score by -0.054661182922\n",
      "Input_149: changes score by -0.134410497454\n",
      "Input_151: changes score by 2.12052597703e-14\n",
      "Input_152: changes score by -0.0548962005484\n",
      "Input_153: changes score by 2.12052597703e-14\n",
      "Input_154: changes score by 2.12052597703e-14\n",
      "Input_155: changes score by 2.12052597703e-14\n",
      "Input_156: changes score by 2.12052597703e-14\n",
      "Input_157: changes score by 2.12052597703e-14\n",
      "Input_158: changes score by 2.12052597703e-14\n",
      "Input_159: changes score by -0.0329220524872\n",
      "Input_160: changes score by -0.00885233059144\n",
      "Input_161: changes score by -0.0749314531923\n",
      "Input_162: changes score by -0.0327653740697\n",
      "Input_163: changes score by 2.12052597703e-14\n",
      "Input_164: changes score by 2.12052597703e-14\n",
      "Input_165: changes score by -0.0441049745397\n",
      "Input_166: changes score by -0.0196435566001\n",
      "Input_167: changes score by -0.0617312965139\n",
      "Input_168: changes score by -0.0927927927928\n",
      "Input_169: changes score by -0.0242264003133\n",
      "Input_171: changes score by -0.0508617312965\n",
      "Input_172: changes score by -0.0424010967489\n",
      "Input_173: changes score by 2.12052597703e-14\n",
      "Input_174: changes score by 2.12052597703e-14\n",
      "Input_175: changes score by -0.0576184880532\n",
      "Input_176: changes score by -0.0260086173129\n",
      "Input_177: changes score by -0.117254210732\n",
      "Input_178: changes score by -0.115315315315\n",
      "Input_179: changes score by -0.035017626322\n",
      "Input_180: changes score by -0.0375048962005\n",
      "Input_181: changes score by -0.0706619663141\n",
      "Input_182: changes score by -0.0508617312965\n",
      "Input_183: changes score by -0.0153740697219\n",
      "Input_184: changes score by 2.12052597703e-14\n",
      "Input_185: changes score by -0.0592440266353\n",
      "Input_186: changes score by -0.046357226792\n",
      "Input_187: changes score by -0.127732079906\n",
      "Input_188: changes score by -0.128280454367\n",
      "Input_189: changes score by -0.0243047395221\n",
      "Input_190: changes score by -0.0529573051312\n",
      "Input_191: changes score by -0.0154524089306\n",
      "Input_193: changes score by 2.12052597703e-14\n",
      "Input_194: changes score by 2.12052597703e-14\n",
      "Input_195: changes score by -0.0399138268703\n",
      "Input_196: changes score by -0.033000391696\n",
      "Input_197: changes score by -0.105679592636\n",
      "Input_198: changes score by -0.0947316882099\n",
      "Input_199: changes score by -0.0220524872699\n",
      "Input_200: changes score by -0.0244614179397\n",
      "Input_201: changes score by -0.0660007833921\n",
      "Input_202: changes score by -0.044026635331\n",
      "Input_203: changes score by 2.12052597703e-14\n",
      "Input_204: changes score by 2.12052597703e-14\n",
      "Input_205: changes score by -0.0442616529573\n",
      "Input_206: changes score by -0.042009400705\n",
      "Input_207: changes score by -0.0992361927144\n",
      "Input_208: changes score by -0.103897375636\n",
      "Input_209: changes score by -0.0221308264786\n",
      "Input_210: changes score by -0.00450450450448\n",
      "Input_211: changes score by -0.0621229925578\n",
      "Input_212: changes score by -0.0507833920877\n",
      "Input_213: changes score by -0.00225225225223\n",
      "Input_215: changes score by -0.059714061888\n",
      "Input_216: changes score by -0.0218958088523\n",
      "Input_217: changes score by -0.101410105758\n",
      "Input_218: changes score by -0.108245201723\n",
      "Input_219: changes score by -0.0176263219741\n",
      "Input_220: changes score by -0.035017626322\n",
      "Input_221: changes score by -0.0394437916177\n",
      "Input_222: changes score by -0.0704269486878\n",
      "Input_224: changes score by 2.12052597703e-14\n",
      "Input_225: changes score by -0.0571484528006\n",
      "Input_226: changes score by -0.0177046611829\n",
      "Input_227: changes score by -0.0378182530356\n",
      "Input_228: changes score by -0.11259302781\n",
      "Input_229: changes score by -0.0462005483744\n",
      "Input_230: changes score by -0.00442616529571\n",
      "Input_231: changes score by -0.0635135135135\n",
      "Input_232: changes score by -0.0686447316882\n",
      "Input_233: changes score by 2.12052597703e-14\n",
      "Input_234: changes score by 2.12052597703e-14\n",
      "Input_235: changes score by -0.0573051312182\n",
      "Input_236: changes score by -0.0503133568351\n",
      "Input_237: changes score by -0.097062279671\n",
      "Input_238: changes score by -0.095045045045\n",
      "Input_239: changes score by -0.023991382687\n",
      "Input_240: changes score by 2.12052597703e-14\n",
      "Input_241: changes score by -0.0771053662358\n",
      "Input_242: changes score by -0.0573834704269\n",
      "Input_243: changes score by 2.12052597703e-14\n",
      "Input_244: changes score by 2.12052597703e-14\n",
      "Input_245: changes score by -0.0507050528789\n",
      "Input_246: changes score by -0.0264786525656\n",
      "Input_247: changes score by -0.114531923228\n",
      "Input_248: changes score by -0.135037211124\n",
      "Input_249: changes score by -0.0154524089306\n",
      "Input_250: changes score by -0.00225225225223\n",
      "Input_251: changes score by -0.0748531139835\n",
      "Input_252: changes score by -0.0547395221308\n",
      "Input_253: changes score by 2.12052597703e-14\n",
      "Input_254: changes score by 2.12052597703e-14\n",
      "Input_255: changes score by -0.0417743830787\n",
      "Input_256: changes score by -0.0176263219741\n",
      "Input_257: changes score by -0.119428123776\n",
      "Input_258: changes score by -0.110575793184\n",
      "Input_259: changes score by -0.0177046611829\n",
      "Input_260: changes score by -0.0153740697219\n",
      "Input_261: changes score by -0.0511750881316\n",
      "Input_262: changes score by -0.0423227575401\n",
      "Input_263: changes score by 2.12052597703e-14\n",
      "Input_264: changes score by 2.12052597703e-14\n",
      "Input_265: changes score by -0.0573051312182\n",
      "Input_266: changes score by -0.0194868781825\n",
      "Input_267: changes score by -0.113141402272\n",
      "Input_268: changes score by -0.0889150019585\n",
      "Input_269: changes score by -0.0397571484528\n",
      "Input_270: changes score by -0.0174696435566\n",
      "Input_271: changes score by -0.0619663141402\n",
      "Input_272: changes score by -0.0420877399138\n",
      "Input_273: changes score by 2.12052597703e-14\n",
      "Input_274: changes score by 2.12052597703e-14\n",
      "Input_275: changes score by -0.0484528006267\n",
      "Input_276: changes score by -0.0196435566001\n",
      "Input_277: changes score by -0.0878965922444\n",
      "Input_278: changes score by -0.0865060712887\n",
      "Just included 18 variables: best score so far is 0.716803760282, with 18 variables used\n",
      "Input_23: changes score by 0.0\n",
      "Input_24: changes score by 0.0\n",
      "Input_25: changes score by 0.0\n",
      "Input_26: changes score by 0.0\n",
      "Input_33: changes score by 0.0\n",
      "Input_35: changes score by 0.0\n",
      "Input_36: changes score by 0.0\n",
      "Input_37: changes score by 0.0\n",
      "Input_38: changes score by 0.0\n",
      "Input_43: changes score by 0.0\n",
      "Input_45: changes score by 0.0\n",
      "Input_47: changes score by 0.0\n",
      "Input_48: changes score by 0.0\n",
      "Input_49: changes score by 0.0\n",
      "Input_50: changes score by 0.0\n",
      "Input_55: changes score by 0.0\n",
      "Input_57: changes score by 0.0\n",
      "Input_58: changes score by 0.0\n",
      "Input_59: changes score by 0.0\n",
      "Input_60: changes score by 0.0\n",
      "Input_61: changes score by 0.0\n",
      "Input_62: changes score by 0.0\n",
      "Input_67: changes score by 0.0\n",
      "Input_69: changes score by 0.0\n",
      "Input_70: changes score by 0.0\n",
      "Input_71: changes score by 0.0\n",
      "Input_72: changes score by 0.0\n",
      "Input_73: changes score by 0.0\n",
      "Input_74: changes score by 0.0\n",
      "Input_81: changes score by 0.0\n",
      "Input_82: changes score by 0.0\n",
      "Input_83: changes score by 0.0\n",
      "Input_84: changes score by 0.0\n",
      "Input_85: changes score by 0.0\n",
      "Input_86: changes score by 0.0\n",
      "Input_91: changes score by 0.0\n",
      "Input_93: changes score by 0.0\n",
      "Input_94: changes score by 0.0\n",
      "Input_96: changes score by 0.0\n",
      "Input_103: changes score by 0.0\n",
      "Input_105: changes score by 0.0\n",
      "Input_106: changes score by 0.0\n",
      "Input_107: changes score by 0.0\n",
      "Input_108: changes score by 0.0\n",
      "Input_115: changes score by 0.0\n",
      "Input_117: changes score by 0.0\n",
      "Input_118: changes score by 0.0\n",
      "Input_119: changes score by 0.0\n",
      "Input_120: changes score by 0.0\n",
      "Input_122: changes score by 0.0\n",
      "Input_127: changes score by 0.0\n",
      "Input_129: changes score by 0.0\n",
      "Input_130: changes score by 0.0\n",
      "Input_131: changes score by 0.0\n",
      "Input_132: changes score by 0.0\n",
      "Input_133: changes score by 0.0\n",
      "Input_134: changes score by 0.0\n",
      "Input_139: changes score by 0.0\n",
      "Input_141: changes score by 0.0\n",
      "Input_142: changes score by 0.0\n",
      "Input_143: changes score by 0.0\n",
      "Input_144: changes score by 0.0\n",
      "Input_145: changes score by 0.0\n",
      "Input_146: changes score by 0.0\n",
      "Input_151: changes score by 0.0\n",
      "Input_153: changes score by 0.0\n",
      "Input_154: changes score by 0.0\n",
      "Input_155: changes score by 0.0\n",
      "Input_156: changes score by 0.0\n",
      "Input_157: changes score by 0.0\n",
      "Input_158: changes score by 0.0\n",
      "Input_163: changes score by 0.0\n",
      "Input_164: changes score by 0.0\n",
      "Input_173: changes score by 0.0\n",
      "Input_174: changes score by 0.0\n",
      "Input_184: changes score by 0.0\n",
      "Input_193: changes score by 0.0\n",
      "Input_194: changes score by 0.0\n",
      "Input_203: changes score by 0.0\n",
      "Input_204: changes score by 0.0\n",
      "Input_224: changes score by 0.0\n",
      "Input_233: changes score by 0.0\n",
      "Input_234: changes score by 0.0\n",
      "Input_240: changes score by 0.0\n",
      "Input_243: changes score by 0.0\n",
      "Input_244: changes score by 0.0\n",
      "Input_253: changes score by 0.0\n",
      "Input_254: changes score by 0.0\n",
      "Input_263: changes score by 0.0\n",
      "Input_264: changes score by 0.0\n",
      "Input_273: changes score by 0.0\n",
      "Input_274: changes score by 0.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-3b8e89871b7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_var\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0mdfa_cols_left\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_var\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_score\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbest_fscore\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mmarg_value_thresh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "#forward search method\n",
    "#note: using f1_weighted gave errors here, so I used regular scoring instead\n",
    "dfa_cols_left = dfa.columns.tolist()\n",
    "dfa_cols_left.remove('Output')\n",
    "\n",
    "knc_foropt = KNeighborsClassifier(n_neighbors = 3, weights = 'distance', n_jobs = -1)\n",
    "\n",
    "# F = []\n",
    "# best_F = []\n",
    "# best_fscore = 0.\n",
    "\n",
    "F = ['Input_90', 'Input_14', 'Input_121', 'Input_98', 'Input_114', 'Input_46', 'Input_223', 'Input_19', 'Input_111', 'Input_75', 'Input_109', 'Input_21', 'Input_102', 'Input_150', 'Input_192', 'Input_170', 'Input_214']\n",
    "best_F = ['Input_90', 'Input_14', 'Input_121', 'Input_98', 'Input_114', 'Input_46', 'Input_223', 'Input_19', 'Input_111', 'Input_75', 'Input_109', 'Input_21', 'Input_102', 'Input_150', 'Input_192', 'Input_170', 'Input_214']\n",
    "best_fscore = 0.716803760282\n",
    "\n",
    "for val in best_F:\n",
    "    dfa_cols_left.remove(val)\n",
    "\n",
    "#threshold for value of adding a variable\n",
    "#set fairly high, since k nearest neighbors (especially with distance weighting) get costlier with increasing dimension\n",
    "# marg_value_thresh = 0.0001\n",
    "# marg_value_thresh = .00001\n",
    "#find that optimal set of variables = 17 inputs, which capture essentially all of the value extractable by a 3NN model\n",
    "#(the current setup of the below loop verifies this, printing out the value of adding a new input to the optimum I found beforehand)\n",
    "#(each input either does not increase the score, or decreases it!)\n",
    "marg_value_thresh = 0.\n",
    "variable_value_thresh = marg_value_thresh\n",
    "while(len(dfa_cols_left) > 0):\n",
    "    print(\"Just included \" + str(len(best_F)) + \" variables: best score so far is \" + str(best_fscore) + \", with \" + str(len(best_F)) + \" variables used\")\n",
    "    Ftest = F\n",
    "    best_score = best_fscore\n",
    "    best_var = \"\"\n",
    "    not_valuable = []\n",
    "    for col in dfa_cols_left:\n",
    "        Ftest.append(col)\n",
    "        currX = np.asarray(dfa[Ftest])\n",
    "        scores = cross_val_score(knc_foropt, currX, y, cv=2)\n",
    "        curr_score = np.mean(scores)\n",
    "        print(col + \": changes score by \" + str(curr_score - best_fscore))\n",
    "        if(curr_score > best_score):\n",
    "            best_score = curr_score\n",
    "            best_var = col\n",
    "        if(curr_score < best_fscore + variable_value_thresh ):\n",
    "            not_valuable.append(col)\n",
    "        Ftest.remove(col)\n",
    "    #remove all columns from consideration which could not improve on the score by more than the variable threshold\n",
    "    #(apart from the best column, if it is one of these)\n",
    "    for column in not_valuable:\n",
    "        if(not(column == best_var)):\n",
    "            dfa_cols_left.remove(column)\n",
    "    \n",
    "    F.append(best_var)\n",
    "    dfa_cols_left.remove(best_var)\n",
    "    \n",
    "    if(best_score > best_fscore+marg_value_thresh):\n",
    "        best_fscore = best_score\n",
    "        best_F = F\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "print(best_F)\n",
    "print(best_fscore)\n",
    "\n",
    "# ['Input_90', 'Input_14', 'Input_121', 'Input_98', 'Input_114', 'Input_46', 'Input_223', 'Input_19']\n",
    "# 0.639306698002\n",
    "\n",
    "# ['Input_90', 'Input_14', 'Input_121', 'Input_98', 'Input_114', 'Input_46', 'Input_223', 'Input_19', 'Input_111', 'Input_75', 'Input_109', 'Input_21']\n",
    "# 0.685663924794\n",
    "\n",
    "# ['Input_90', 'Input_14', 'Input_121', 'Input_98', 'Input_114', 'Input_46', 'Input_223', 'Input_19', 'Input_111', 'Input_75', 'Input_109', 'Input_21', 'Input_102', 'Input_150', 'Input_192', 'Input_170']\n",
    "# 0.714629847239\n",
    "\n",
    "#marginal increase after this was relatively small; adding Input_214 added ~.0022 to score, adding further variables apparently did not increase score\n",
    "#(since variable-additions were not accepted even with threshold = 0.)\n",
    "\n",
    "\n",
    "# ['Input_90', 'Input_14', 'Input_121', 'Input_98', 'Input_114', 'Input_46', 'Input_223', 'Input_19', 'Input_111', 'Input_75', 'Input_109', 'Input_21', 'Input_102', 'Input_150', 'Input_192', 'Input_170', 'Input_214']\n",
    "# 0.716803760282"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=3, p=2,\n",
      "           weights='distance')\n",
      "0.66291524946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "F_touse = ['Input_90', 'Input_14', 'Input_121', 'Input_98', 'Input_114', 'Input_46', 'Input_223', 'Input_19', 'Input_111', 'Input_75', 'Input_109', 'Input_21', 'Input_102', 'Input_150', 'Input_192', 'Input_170', 'Input_214']\n",
    "X_best = np.asarray(dfa[F_touse])\n",
    "\n",
    "# n_neighbors = [3,10,30,100]\n",
    "# best was 3,distance, with a score of .6629\n",
    "#(note: when only uniform was tested, n=3 was still best, but score was .5855)\n",
    "#(similarly, when standard scoring rather than f1_weighted was used, 3,distance was still optimal)\n",
    "\n",
    "# n_neighbors = [1,2,3,5,8]\n",
    "#best was still 3, distance\n",
    "\n",
    "n_neighbors = [3,4,6,7]\n",
    "#again, 3,distance best\n",
    "weights = ['uniform','distance']\n",
    "\n",
    "\n",
    "search_grid = {'n_neighbors':n_neighbors, 'weights': weights}\n",
    "\n",
    "gscv = GridSearchCV(knc,search_grid, cv=2, scoring = 'f1_weighted')\n",
    "gscv.fit(X_best,y)\n",
    "print(gscv.best_estimator_)\n",
    "print(gscv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Ashwin\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "lc_sizes, train_scores, test_scores = learning_curve(knc_o, X_best, y, cv = 2, scoring = 'f1_weighted')\n",
    "train_avg = np.average(train_scores,axis=1)\n",
    "test_avg = np.average(test_scores,axis=1)\n",
    "\n",
    "nvarsused = str(len(best_F))\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(lc_sizes, train_avg, 'go')\n",
    "plt.plot(lc_sizes, test_avg, 'ro')\n",
    "plt.title(\"Arrhythmia - kNN Learning Curve - f1_weighted scoring - \" + nvarsused + \" variables\")\n",
    "plt.savefig(\"knn_learningcurve_\" + nvarsused + \"vars\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we can see that the reduced-variable kNN model has some bias (score on training set is non-negligibly smaller than 1)\n",
    "#however, variance (difference between training and test scores) still predominates\n",
    "#final training + test scores look very similar to those of logistic regression, though test score is slightly better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Summary of results (average score for 2-fold cross-validation)\n",
    "#initial kNN (k=3): .4945\n",
    "#logistic regression: .6569\n",
    "#reduced-variable kNN (k=3): .6629\n",
    "#since the reduced-variable kNN scores slightly better, I would recommend it as a classifier.\n",
    "#However, in general, the logistic regression seems somewhat safer for low-effort analyses\n",
    "#since the kNN model requires some costly optimization over variables (and k) to beat it, and takes more time to predict as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5e\n",
    "#variance of score as k increases\n",
    "#stratified k-fold throws errors if more than 2-fold cross-validation is used, since there are few instances of some output classes\n",
    "#as a result, I will use unstratified 5-fold cross-validations and take the variance of the results\n",
    "from sklearn.cross_validation import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 0.00101241287493; std of subvariances is 0.000689929282184\n",
      "2: 0.000618490093194; std of subvariances is 0.000415941858886\n",
      "3: 0.00151029837889; std of subvariances is 0.000702121138823\n",
      "4: 0.000560879865299; std of subvariances is 0.000181050409115\n",
      "5: 0.000651969613909; std of subvariances is 0.000420888977505\n",
      "6: 0.000622405826611; std of subvariances is 0.000638813834531\n",
      "7: 0.000481635210275; std of subvariances is 0.000408596509453\n",
      "8: 0.000495340277234; std of subvariances is 0.000340640675837\n",
      "9: 0.000477474743519; std of subvariances is 0.000334291407312\n",
      "10: 0.000697930534889; std of subvariances is 0.00073543585784\n",
      "11: 0.000952453206986; std of subvariances is 0.00139435517577\n",
      "12: 0.000656815334012; std of subvariances is 0.000485831368566\n",
      "13: 0.000970074007362; std of subvariances is 0.00064151157889\n",
      "14: 0.000782118803352; std of subvariances is 0.000722421145296\n",
      "15: 0.000358828020988; std of subvariances is 0.00041215332212\n",
      "16: 0.000807571070562; std of subvariances is 0.000980064470063\n",
      "17: 0.000836547497846; std of subvariances is 0.000747518182147\n",
      "18: 0.000405082621975; std of subvariances is 0.000421971376982\n",
      "19: 0.000333375753779; std of subvariances is 0.000269235593887\n",
      "20: 0.00108348343645; std of subvariances is 0.000785452348365\n",
      "21: 0.000771937896468; std of subvariances is 0.000548964537021\n",
      "22: 0.000766455869684; std of subvariances is 0.000741041718724\n",
      "23: 0.000810752603963; std of subvariances is 0.000788655832075\n",
      "24: 0.000634887226878; std of subvariances is 0.000424767123886\n",
      "25: 0.00078172723001; std of subvariances is 0.000494978607312\n",
      "26: 0.00123228130629; std of subvariances is 0.00154098351719\n",
      "27: 0.000797390163678; std of subvariances is 0.00097053836846\n",
      "28: 0.000758232829509; std of subvariances is 0.000558189695663\n",
      "29: 0.000801942203775; std of subvariances is 0.000526526018366\n",
      "40: 0.000699496828256; std of subvariances is 0.000697176685829\n",
      "45: 0.000596170412718; std of subvariances is 0.000661621361153\n",
      "50: 0.00124300062652; std of subvariances is 0.00103652644474\n",
      "55: 0.00125200681338; std of subvariances is 0.000932536275564\n",
      "60: 0.000660780014097; std of subvariances is 0.000639031317884\n",
      "65: 0.00126282402694; std of subvariances is 0.00124496693643\n",
      "70: 0.000589317879239; std of subvariances is 0.000653445163414\n",
      "75: 0.00058716422586; std of subvariances is 0.000656902940844\n",
      "80: 0.00100296616806; std of subvariances is 0.000853015725666\n",
      "90: 0.000485355157021; std of subvariances is 0.000496565331028\n",
      "100: 0.000730480068917; std of subvariances is 0.000734571916147\n",
      "200: 0.000775511003211; std of subvariances is 0.000473386906629\n"
     ]
    }
   ],
   "source": [
    "variances = []\n",
    "nrows_arr = len(y)\n",
    "\n",
    "n_fold = 3\n",
    "n_fold_strat = 2\n",
    "# ks = [1,2,3,4,5,8,10,15,20,30,100,200]\n",
    "ks = np.asarray(range(1,30)).tolist()\n",
    "ks += [40,45,50,55,60,65,70,75,80,90,100,200]\n",
    "\n",
    "loops_per = 10\n",
    "for k in ks:\n",
    "    knc_k = KNeighborsClassifier(n_neighbors = k, weights = 'distance', n_jobs = -1)\n",
    "    k_scores = []\n",
    "    subvars = []\n",
    "    for loop in range(0,loops_per):\n",
    "#         cv_curr = KFold(nrows_arr, n_folds = n_fold, shuffle = True)\n",
    "        cv_curr = KFold(nrows_arr, n_folds = n_fold_strat, shuffle = True)\n",
    "        curr_scores = cross_val_score(knc_k, X_best, y, cv=cv_curr)\n",
    "        subvars.append(np.var(curr_scores))\n",
    "        k_scores += curr_scores.tolist()\n",
    "    k_var = np.var(k_scores)\n",
    "    variances.append(k_var)\n",
    "    print(str(k) + \": \" + str(k_var) + \"; std of subvariances is \" + str(np.var(subvars)**.5))\n",
    "plt.clf()\n",
    "plt.plot(ks,variances,'b-')\n",
    "plt.title(\"Variance of \" + str(3) + \"-fold cross-validation of reduced-input kNN model vs k\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Cross-validation Variance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.plot(ks,variances,'b-')\n",
    "plt.title(\"Variance of \" + str(3) + \"-fold cross-validation of reduced-input kNN model vs k\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Cross-validation Variance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(452, 17)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_best.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
